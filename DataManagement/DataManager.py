#! /usr/bin/python3

import pandas as pd
import psycopg2
from psycopg2 import sql
import numpy as np
import dateutil
from sqlalchemy import create_engine
from os import listdir
from DataManagement import DbUtils, Converters
from multiprocessing import Pool


class DbInitiator:

    def __init__(self, config):
        self.config = config
        self.p = Pool(self.config['processors'])
        self.con = psycopg2.connect(database=self.config['database'], user=self.config['user'],
                                    host=self.config['host'])
        self.cur = self.con.cursor()
        self.con_sql_alchemy = create_engine(self.config['url'])

    def __enter__(self):
        return self

    def __exit__(self):
        self.con_sql_alchemy.close()
        self.con.close()

    def init_db(self):
        """Initiates the database. Transform and populate data from all CVS located in input folder"""
        self.cur.execute("""CREATE TABLE IF NOT EXISTS public.teams(
                    team_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    team_name text,
                    CONSTRAINT team_name_uniq UNIQUE (team_name)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.teams OWNER TO footdata;
                    """
                         )

        self.cur.execute("""CREATE TABLE IF NOT EXISTS public.countries(
                    country_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    country_name text,
                    CONSTRAINT country_name_uniq UNIQUE (country_name)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.countries OWNER TO footdata;
                    """
                         )

        self.cur.execute("""CREATE TABLE IF NOT EXISTS public.leagues(
                    league_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    league_name text,
                    CONSTRAINT league_name_uniq UNIQUE (league_name)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.leagues OWNER TO footdata;
                    """
                         )

        self.cur.execute("""CREATE TABLE IF NOT EXISTS public.matches(
                    match_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    date timestamp without time zone,
                    home_team_id int REFERENCES teams (team_id),
                    away_team_id int REFERENCES teams (team_id),
                    fthg int,
                    ftag int,
                    ftr int,
                    hthg int,
                    htag int,
                    htr int,
                    b365h double precision,
                    b365d double precision,
                    b365a double precision,
                    league_id int REFERENCES leagues (league_id),
                    country_id int REFERENCES countries (country_id),
                    htftr int,
                    previous_home_match_id int,
                    previous_away_match_id int,
                    CONSTRAINT date_home_uniq UNIQUE (date, home_team_id)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.matches OWNER TO footdata;
                    """
                         )

        self.cur.execute(""" CREATE INDEX IF NOT EXISTS match_id ON matches (match_id);
                            CREATE INDEX IF NOT EXISTS home_team_id ON matches (home_team_id);
                            CREATE INDEX IF NOT EXISTS away_team_id ON matches (away_team_id);
                            CREATE INDEX IF NOT EXISTS date ON matches (date);""")
        self.con.commit()

    def init_feature_db(self, count):
        """
        :param count: number of last matches to generate features on
        :return: N/A
        """
        self.cur.execute("""
                        CREATE TABLE IF NOT EXISTS features{0}_matches (
                          match_id    int REFERENCES matches (match_id) ON UPDATE CASCADE ON DELETE CASCADE, 
                          CONSTRAINT match_side_previous_{0}_pkey PRIMARY KEY (match_id, previous_id, side)
                        );""".format(count))
        self.cur.execute('CREATE INDEX IF NOT EXISTS match_side_{0}_index ON matches_{0}_previous (match_id, side);'.
                         format(count))
        self.con.commit()


class FileImporter:

    def __init__(self, config):
        self.config = config
        self.p = Pool(self.config['processors'])
        self.con = psycopg2.connect(database=self.config['database'], user=self.config['user'],
                                    host=self.config['host'])
        self.cur = self.con.cursor()
        self.con_sql_alchemy = create_engine(self.config['url'])
        self.db_initiator = DbInitiator(config)

    def __enter__(self):
        return self

    def __exit__(self):
        self.con_sql_alchemy.close()
        self.con.close()

    def update_countries(self, matches):
        countries_unique = DbUtils.clean_df_db_duplicates(matches[['country_name']].drop_duplicates(), "countries",
                                                          self.con_sql_alchemy, dup_cols=["country_name"])

        countries_unique.to_sql('countries', self.con_sql_alchemy, index=False, if_exists='append')

        countries_updated = pd.read_sql_query('SELECT * FROM countries;', self.con, index_col='country_name')

        matches = matches.merge(countries_updated, left_on='country_name', right_on='country_name')
        matches = matches.drop('country_name', axis=1)
        return matches

    def update_leagues(self, matches):
        leagues_unique = DbUtils.clean_df_db_duplicates(matches[['league_name']].drop_duplicates(), "leagues",
                                                        self.con_sql_alchemy, dup_cols=["league_name"])

        leagues_unique.to_sql('leagues', self.con_sql_alchemy, index=False, if_exists='append')

        leagues_updated = pd.read_sql_query('SELECT * FROM leagues;', self.con, index_col='league_name')

        matches = matches.merge(leagues_updated, left_on='league_name', right_on='league_name')
        matches = matches.drop('league_name', axis=1)

        return matches

    def update_teams(self, matches):
        teams = (matches[['home_team_name']].rename(columns={'home_team_name': 'team_name'}).append(
            matches[['away_team_name']].rename(columns={'away_team_name': 'team_name'}), ignore_index=True)) \
            .drop_duplicates()

        teams_unique = DbUtils.clean_df_db_duplicates(teams, "teams",
                                                      self.con_sql_alchemy, dup_cols=["team_name"])

        teams_unique.to_sql('teams', self.con_sql_alchemy, index=False, if_exists='append')

        teams_updated = pd.read_sql_query('SELECT * FROM teams;', self.con, index_col='team_name')

        matches = matches.merge(teams_updated.rename(columns={'team_id': 'home_team_id'}), left_on='home_team_name',
                                right_on='team_name')

        matches = matches.merge(teams_updated.rename(columns={'team_id': 'away_team_id'}), left_on='away_team_name',
                                right_on='team_name')

        matches = matches.drop((['home_team_name', 'away_team_name']), axis=1)

        return matches

    def import_files(self):
        self.db_initiator.init_db()
        csv_files = listdir(self.config['source_directory'])

        converters = Converters()

        matches_list_frames = []

        for csv_file in csv_files:
            temp_frame = pd.read_csv(('%s/{0}' % self.config['source_directory']).format(csv_file))
            temp_frame.dropna(how='all', inplace=True)  # Remove empty rows
            temp_frame.dropna(axis=1, how='all', inplace=True)  # Remove empty columns
            temp_frame.dropna(subset=['HTR', 'FTR'],
                              inplace=True)  # Remove matches without half time or full time results
            temp_frame['league'] = temp_frame['Div']  # Create new column for league name
            temp_frame['country'] = temp_frame['Div']  # Create new column for country name
            temp_frame.Date = self.p.map(converters.convert_date, temp_frame.Date)
            temp_frame.country = self.p.map(converters.country, temp_frame.country)
            temp_frame.league = self.p.map(converters.league, temp_frame.league)
            temp_frame.HTR = self.p.map(converters.h_d_a, temp_frame.HTR)
            temp_frame.FTR = self.p.map(converters.h_d_a, temp_frame.FTR)
            temp_frame['HTFTR'] = self.p.map(int, temp_frame['HTR'].map(str) + temp_frame['FTR'].map(str))
            temp_frame.drop(
                ['HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'Div', 'BWH', 'BWD',
                 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', 'LBA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'VCH',
                 'VCD', 'VCA', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA', 'BbOU', 'BbMx>2.5',
                 'BbAv>2.5', 'BbMx<2.5', 'BbAv<2.5', 'BbAH', 'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA',
                 'PSCH', 'PSCD', 'PSCA', 'BSH', 'BSD', 'BSA', 'Referee', 'GBH', 'GBA', 'GBD', 'SBH', 'SBD', 'SBA',
                 'SJH', 'SJD', 'SJA'], axis=1, inplace=True, errors='ignore')
            temp_frame.replace("", np.nan)
            temp_frame.columns = ['date', 'home_team_name', 'away_team_name', 'fthg', 'ftag', 'ftr', 'hthg', 'htag',
                                  'htr',
                                  'b365h', 'b365d', 'b365a', 'league_name', 'country_name', 'htftr']

            matches_list_frames.append(temp_frame)

        matches = pd.concat(matches_list_frames, axis=0, ignore_index=True)

        matches = self.update_countries(matches)
        matches = self.update_leagues(matches)
        matches = self.update_teams(matches)

        matches_unique = DbUtils.clean_df_db_duplicates(matches,
                                                        "matches",
                                                        self.con_sql_alchemy, dup_cols=["date", "home_team_id"],
                                                        log=True)

        matches_unique.to_sql('matches', self.con_sql_alchemy, index=False, if_exists='append')

        self.update_previous_matches()
        self.generate_features(5)

    def update_previous_matches(self):
        """
        Get last &count matches of both teams.
        """

        self.cur.execute("""UPDATE matches 
        SET previous_home_match_id = (SELECT match_id FROM matches AS m
        WHERE (home_team_id = matches.home_team_id OR away_team_id = matches.home_team_id) AND date < matches.date
        ORDER BY date DESC 
        LIMIT 1)
        WHERE previous_home_match_id IS NULL;""")

        self.cur.execute("""UPDATE matches
        SET previous_away_match_id = (SELECT match_id FROM matches AS m
        WHERE (away_team_id = matches.away_team_id OR home_team_id = matches.away_team_id) AND date < matches.date
        ORDER BY date DESC 
        LIMIT 1)
        WHERE previous_away_match_id IS NULL;""")
        self.con.commit()

    def generate_features(self, count):
        """
        :return:
        """

        side_column = {'home': 'previous_home_match_id', 'away': 'previous_away_match_id'}

        def get_matches_without_features():
            table_name = "features_last_" + count.__str__() + "_matches"

            query = sql.SQL("""SELECT matches.match_id, matches.b365h, matches.b365d, 
            matches.b365a, matches.previous_home_match_id, matches.previous_away_match_id 
            FROM matches 
            LEFT JOIN {} features ON features.match_id = matches.match_id 
            WHERE features.match_id IS NULL;""").format(sql.Identifier(table_name)).as_string(self.con)

            return pd.read_sql_query(query, self.con_sql_alchemy,
                                     index_col='match_id')

        def get_features(side):

            matches_list_frames = []
            for match in matches_without_features[side_column[side]]:
                result = get_last_matches(match, side)
                if not result.empty:
                    matches_list_frames.append(result)

            matches = pd.concat(matches_list_frames)
            matches.groupby('base_match_id', sort=False).agg({'fthg': 'mean'})

        def get_last_matches(match, side):
            query = sql.SQL("""WITH RECURSIVE previous_matches  AS (
            SELECT matches.*, 1 AS depth FROM matches 
            WHERE matches.match_id = %(match_id)s
            UNION ALL
            SELECT matches.*,  previous_matches.depth + 1 
            FROM matches, previous_matches 
            WHERE matches.match_id = previous_matches.{} 
            AND depth < %(count)s)
            SELECT * FROM previous_matches;""").format(sql.Identifier(side_column[side])).as_string(self. con)

            params = {'match_id': match,
                      'count': count}

            previous_matches_df = pd.read_sql_query(query, self.con, index_col='match_id', params=params)
            previous_matches_df.drop(['depth', 'previous_home_match_id', 'previous_away_match_id', 'league_id',
                                      'country_id'], axis=1, inplace=True)
            previous_matches_df['base_match_id'] = match

            return previous_matches_df

        matches_without_features = get_matches_without_features()
        print(get_features('home'))



