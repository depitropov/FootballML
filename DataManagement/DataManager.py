#! /usr/bin/python3

import pandas as pd
import psycopg2
import logging
import numpy as np
from sqlalchemy import create_engine
from os import listdir
from Football.getters import set_last_matches
from DataManagement import Converters
from multiprocessing import Pool
from sqlalchemy.exc import IntegrityError


class DbInitiator:

    def __init__(self, config):
        self.config = config

    def init_db(self):
        """Initiates the database. Transform and populate data from all CVS located in input folder"""
        conn = psycopg2.connect(database=self.config['database'], user=self.config['user'], host=self.config['host'])
        cur = conn.cursor()
        cur.execute("""CREATE TABLE IF NOT EXISTS public.teams(
                    team_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    team_name text,
                    CONSTRAINT team_name_uniq UNIQUE (team_name)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.teams OWNER TO footdata;
                    """
                    )
        cur.execute("""CREATE TABLE IF NOT EXISTS public.countries(
                    country_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    country_name text,
                    CONSTRAINT country_name_uniq UNIQUE (country_name)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.countries OWNER TO footdata;
                    """
                    )
        cur.execute("""CREATE TABLE IF NOT EXISTS public.leagues(
                    league_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    league_name text,
                    CONSTRAINT league_name_uniq UNIQUE (league_name)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.leagues OWNER TO footdata;
                    """
                    )
        cur.execute("""CREATE TABLE IF NOT EXISTS public.matches(
                    match_id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                    date timestamp without time zone,
                    home_team_id int REFERENCES teams (team_id),
                    away_team_id int REFERENCES teams (team_id),
                    fthg int,
                    ftag int,
                    ftr int,
                    hthg int,
                    htag int,
                    htr int,
                    b365h double precision,
                    b365d double precision,
                    b365a double precision,
                    league_id int REFERENCES leagues (league_id),
                    country_id int REFERENCES countries (country_id),
                    htftr int,
                    CONSTRAINT date_home_uniq UNIQUE (date, home_team_id)
                    )
                    WITH (OIDS = FALSE);
                    ALTER TABLE public.matches OWNER TO footdata;
                    """
                    )
        conn.commit()
        conn.close()

    def init_previous_matches_db(self, count):
        conn = psycopg2.connect(database=self.config['database'], user=self.config['user'], host=self.config['host'])
        cur = conn.cursor()

        cur.execute("""
                        CREATE TABLE IF NOT EXISTS matches_{0}_previous (
                          match_id    int REFERENCES matches (match_id) ON UPDATE CASCADE ON DELETE CASCADE, 
                          previous_id int REFERENCES matches (match_id) ON UPDATE CASCADE, 
                          side text, 
                          CONSTRAINT match_side_previous_pkey PRIMARY KEY (match_id, previous_id, side)
                        );""".format(count))
        conn.commit()
        conn.close()


class FileImporter:

    def __init__(self, config):
        self.config = config
        self.p = Pool(self.config['processors'])
        self.con = psycopg2.connect(database=self.config['database'], user=self.config['user'],
                                    host=self.config['host'])
        self.con_sql_alchemy = create_engine(self.config['url'])

    def __enter__(self):
        return self

    def __exit__(self):
        self.con_sql_alchemy.close()
        self.con.close()

    def update_countries(self, matches):
        countries = pd.read_sql_query('SELECT country_name FROM countries;', self.con)
        matches_countries = matches[['country_name']].drop_duplicates()

        key_diff = set(matches_countries.country_name).difference(countries.country_name)
        where_diff = matches_countries.country_name.isin(key_diff)

        countries_to_be_added = matches_countries[where_diff]

        countries_to_be_added.to_sql('countries', self.con_sql_alchemy, index=False, if_exists='append')

        countries_updated = pd.read_sql_query('SELECT * FROM countries;', self.con, index_col='country_name')

        matches = matches.merge(countries_updated, left_on='country_name', right_on='country_name')
        matches = matches.drop('country_name', axis=1)
        return matches

    def update_leagues(self, matches):
        leagues = pd.read_sql_query('SELECT league_name FROM leagues;', self.con)
        matches_leagues = matches[['league_name']].drop_duplicates()

        key_diff = set(matches_leagues.league_name).difference(leagues.league_name)
        where_diff = matches_leagues.league_name.isin(key_diff)

        leagues_to_be_added = matches_leagues[where_diff]

        leagues_to_be_added.to_sql('leagues', self.con_sql_alchemy, index=False, if_exists='append')

        leagues_updated = pd.read_sql_query('SELECT * FROM leagues;', self.con, index_col='league_name')

        matches = matches.merge(leagues_updated, left_on='league_name', right_on='league_name')
        matches = matches.drop('league_name', axis=1)
        return matches

    def update_teams(self, matches):
        team = pd.read_sql_query('SELECT team_name FROM teams;', self.con)
        matches_teams = (matches[['home_team_name']].rename(columns={'home_team_name': 'team_name'}).append(
            matches[['away_team_name']].rename(columns={'away_team_name': 'team_name'}), ignore_index=True)) \
            .drop_duplicates()

        key_diff = set(matches_teams.team_name).difference(team.team_name)
        where_diff = matches_teams.team_name.isin(key_diff)

        teams_to_be_added = matches_teams[where_diff]

        teams_to_be_added.to_sql('teams', self.con_sql_alchemy, index=False, if_exists='append')

        teams_updated = pd.read_sql_query('SELECT * FROM teams;', self.con, index_col='team_name')

        matches = matches.merge(teams_updated.rename(columns={'team_id': 'home_team_id'}), left_on='home_team_name',
                                right_on='team_name')

        matches = matches.merge(teams_updated.rename(columns={'team_id': 'away_team_id'}), left_on='away_team_name',
                                right_on='team_name')

        matches = matches.drop((['home_team_name', 'away_team_name']), axis=1)
        return matches

    def import_files(self):
        csv_files = listdir(self.config['source_directory'])

        converters = Converters()

        matches_list_frames = []

        for csv_file in csv_files:
            temp_frame = pd.read_csv(('%s/{0}' % self.config['source_directory']).format(csv_file))
            temp_frame.dropna(how='all', inplace=True)  # Remove empty rows
            temp_frame.dropna(axis=1, how='all', inplace=True)  # Remove empty columns
            temp_frame.dropna(subset=['HTR', 'FTR'],
                              inplace=True)  # Remove matches without half time or full time results
            temp_frame['league'] = temp_frame['Div']  # Create new column for league name
            temp_frame['country'] = temp_frame['Div']  # Create new column for country name
            temp_frame.Date = self.p.map(converters.convert_date, temp_frame.Date)
            temp_frame.country = self.p.map(converters.country, temp_frame.country)
            temp_frame.league = self.p.map(converters.league, temp_frame.league)
            temp_frame.HTR = self.p.map(converters.h_d_a, temp_frame.HTR)
            temp_frame.FTR = self.p.map(converters.h_d_a, temp_frame.FTR)
            temp_frame['HTFTR'] = self.p.map(int, temp_frame['HTR'].map(str) + temp_frame['FTR'].map(str))
            temp_frame.drop(
                ['HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'Div', 'BWH', 'BWD',
                 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', 'LBA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'VCH',
                 'VCD', 'VCA', 'Bb1X2', 'BbMxH', 'BbAvH', 'BbMxD', 'BbAvD', 'BbMxA', 'BbAvA', 'BbOU', 'BbMx>2.5',
                 'BbAv>2.5', 'BbMx<2.5', 'BbAv<2.5', 'BbAH', 'BbAHh', 'BbMxAHH', 'BbAvAHH', 'BbMxAHA', 'BbAvAHA',
                 'PSCH', 'PSCD', 'PSCA', 'BSH', 'BSD', 'BSA', 'Referee', 'GBH', 'GBA', 'GBD', 'SBH', 'SBD', 'SBA',
                 'SJH', 'SJD', 'SJA'], axis=1, inplace=True, errors='ignore')
            temp_frame.replace("", np.nan)
            temp_frame.columns = ['date', 'home_team_name', 'away_team_name', 'fthg', 'ftag', 'ftr', 'hthg', 'htag',
                                  'htr',
                                  'b365h', 'b365d', 'b365a', 'league_name', 'country_name', 'htftr']

            matches_list_frames.append(temp_frame)

        matches_data_frame = pd.concat(matches_list_frames, axis=0, ignore_index=True)

        matches_data_frame = self.update_countries(matches_data_frame)
        matches_data_frame = self.update_leagues(matches_data_frame)
        matches_data_frame = self.update_teams(matches_data_frame)

        try:
            matches_data_frame.to_sql('matches', self.con_sql_alchemy, if_exists='append', index=False)
        except IntegrityError as e:
            logging.warning('Cannot import all Matches to database error: \n {0}'.format(e))

        cur = self.con.cursor()
        cur.execute("""DROP INDEX match_id;
                    DROP INDEX home_team_id;
                    DROP INDEX away_team_id;
                    DROP INDEX date;
                    CREATE INDEX match_id ON matches (match_id);
                    CREATE INDEX home_team_id ON matches (home_team_id);
                    CREATE INDEX away_team_id ON matches (away_team_id);
                    CREATE INDEX date ON matches (date);
                    """
                    )
        self.con.commit()

    def update_last_matches(self):
        matches = pd.read_sql_query('SELECT * FROM matches', self.con, index_col='match_id')
        set_last_matches(matches, self.con)

    def set_additional_data(self):
        """Populate additional data to existing DB. Adds last matches and ids for country, league and teams"""
        cur = self.con.cursor()
        matches = pd.read_sql_query('SELECT * FROM matches', self.con)
        conn = create_engine(self.config['url'])
        # matches['country_id'] = pd.Categorical((pd.factorize(matches.country)[0] + 1))
        # matches['league_id'] = pd.Categorical((pd.factorize(matches.league)[0] + 1))
        # matches['home_id'] = pd.Categorical((pd.factorize(matches.HomeTeam)[0] + 1))
        # unique_teams = matches[['HomeTeam', 'home_id']].drop_duplicates()
        # unique_teams.columns = ['AwayTeam', 'away']
        # unique_teams.to_sql('teams', conn, index=False, if_exists='replace')
        # matches = matches.merge(unique_teams, left_on='AwayTeam', right_on='AwayTeam')
        # matches = matches.rename(columns={'away': 'away_id'})
        set_last_matches(matches)
        # matches['last_home_ids_10'] = p.map(getters.get_10last_home, matches['Date'], matches['HomeTeam'])
        # matches['last_away_ids_10'] = p.map(getters.get_10last_away, matches['Date'], matches['AwayTeam'])
        # matches['last_home_ids_5'] = p.map(getters.get_5last_home, matches['Date'], matches['HomeTeam'])
        # matches['last_away_ids_5'] = p.map(getters.get_5last_away, matches['Date'], matches['AwayTeam'])
        # matches['last_direct'] = p.map(getters.get_last_direct, matches['Date'],zip(matches['HomeTeam'], matches['AwayTeam']))

        matches.to_sql('matches', conn, if_exists='append', index=False)
        conn.close()
